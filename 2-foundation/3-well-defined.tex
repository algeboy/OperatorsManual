
\section{Operations are well-defined}
The most important aspect of functions to preserve is the reliability of evaluation.
\begin{align*}
    x=\acute{x} & \Rightarrow f(x)=f(\acute{x}).
\end{align*}
There are of course witty counter-examples.
\begin{align*}
    f\left(\frac{a}{b}\right)\defeq a+b.
\end{align*}
Then using $1/2=2/4$ we find that
\begin{align*}
    1/2 = 2/4 & \Rightarrow 1+2=f(1/2)=f(2/4)=2+4.
\end{align*}
In the exercises you can unwind how this is mostly the 
usual mistake of using nominal judgement ($\defeq$) 
instead of operator abstraction ($\mapsto$) to lead 
to a confusion between a function and a straight-forward substitution.
That is, there is no magic here just misuse of notation.
Yet, what about the confidence we place in functions like $f(x)=x+2$.
Here at best we base our judgement on $+$ being a function, that is, 
equal inputs give equal outputs.  If these are more primitive notation 
they will eventually depend on our most primitive $\lambda$-calculus 
for confidence.

First we should address when to stop an evaluation.
\begin{definition}
    \begin{itemize}
        \item If $G$ and $F$ are strings and there are strings 
        $G_1,\ldots,G_{\ell}$ such that 
        \[ G=G_1 \leadsto G_2 \leadsto\cdots\leadsto G_{\ell}=F\]
        then write $G\leadsto F$.

        \item if $G\leadsto H$ and $F\leadsto H$ then write $G\betaeq H$.
        In particular $G\betaeq F$ if after renaming variables and doing some reductions 
        they agree.

        \item A formula $F$ is \emph{reduced} when it has no terms where 
        $(x\mapsto M)N$.  
    
    \end{itemize}
    
\end{definition}

\subsection{Confluence and Normal Forms}
\begin{theorem}[Church-Rosser]
    If $L\leadsto_{\beta} M$ and $L\leadsto N$ then there is $O$ such that 
    \[M\leadsto_{\beta} O\qquad N\leadsto_{\beta} O.\] 
    In particular, if $F\leadsto S,R$ where both $R$ and $S$ are reduced,
    then $R\betaeq S$ (that is equal up to possibly renaming a variable).
\end{theorem}

This is the first of many \emph{normal-form} theorems in algebra.
Normal forms are unique representations given after rewriting a formula.


\begin{definition}
    A operator is a sentence in $\lambda$-calculus.
    Evaluating an operator is to apply $\beta$-reductions.
\end{definition}

\begin{corollary}
    If a operator evaluates in finite time then whatever process it uses 
    gives the same answer.
\end{corollary}



It is the job of a programming language to implement a version 
of substitution that follows these rules.  Once done the notation will take 
on the usual character of the programming language but often the notation 
comes close to the mathematical notations.  Here are some popular variations to try.
\begin{center}
    \code{lambda x.x+2}
    \hspace{1cm}
    \code{x => x+2}
    \hspace{1cm}
    \code{x |-> x+2}\\
    \code{func(x)=x+2}
    \hspace{1cm}
    \code{(x)-> {return x+2}}
\end{center} 


So our traditional $f(x)\defeq M$ notation would no be hinting at 
$f:x\mapsto M$ in our notation, and the $f$ here would be naming 
the specific example $x\mapsto M$, which is often helpful.  Yet 
we should not take this correspondence too far since we have already 
seen the ways in which substituting for $x$ in $f(x)\defeq M$ notation 
goes astray.

The first rule Bound.match may at first seem odd.  Aren't we trying to place $x$?
Yes but when we write $x\mapsto M$ we are declaring $x$ as a local variable.  
It is completely meaningless what it is called outside the scope of $M$.
It is the same thing we come to expect when we do things like this:


In some situations the role of bound/local variables is further 
restricted to roles of a decidedly special meaning, for example, as indices that 
run through a range.
\begin{align*}
    \sum_{i=1}^{10} i^2 \qquad \prod_{i\in I}X_i 
\end{align*}
or in code 
\begin{center}
\begin{Pcode}[]
def sum(ns)= {
  x = 0
  for n in ns 
    x = x + n
  x  
}

x = [2,3,4]
sum(x)  // the x outside is not the x inside sum
\end{Pcode}
\end{center}