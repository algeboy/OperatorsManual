
\section{Valence}
\index{variadic}
We can add any finite list of $\sum_{i} n_i$ and 
programs back this up with commands like \code{sum(ns)} 
(the convention in programs is that a sequence $n_*$ is transcribed as 
the plural \code{ns}).  Likewise we can concatenate any 
number of strings.  In reality though, we have a limited work force:
ourselves and our machines. We therefore end up adding a bounded number at once,
often just 2.  So while we can entertain addition as having 
\emph{variadic} (variable valence), it is a practical reality that 
we build up arbitrary valance by composing several operators of 
fixed valence.

\index{bivalent!opeator}\index{binary operator|see{bivalent operator}}
Addition from here on out will be bivalent (also called binary), meaning 
that it requires 2 inputs.  We typically prefer infix grammar $\Box +\Box$.
Since we are evolving, we may as well permit multiplication as a bivalent operator
symbol, changing the signature to $\Box \cdot \Box$, i.e. $2\cdot 4$; or
$\Box\Box$, e.g. $xy$.   Avoid $\Box\times \Box$, we need that symbol elsewhere.
These days composition $\Box\circ\Box$ is written as multiplication; so, you can
use that symbol however you like.  Addition is held to high standards in algebra
(that it will evolve into linear algebra).  So when you are considering a binary
operation with few if any good properties, use a multiplication inspired
notation instead.   




\index{univalent!opeator}\index{unary operator|see{univalent operator}}
Valence 1, also called \emph{univalent} or \emph{unary}, operators include the negative sign $-\Box$ to create 
$-2$ as well as the transpose $A^{\dagger}$ of a matrix $A$.
Notice in the case of negative an integer remained an integer, but
 in the case of transpose a $(2\times 3)$-matrix becomes a $(3\times 2)$-matrix.   Operators can change the type of data we explore.
 
Programming languages add several others univalent operators
such as \code{++i, --i} which are said to \emph{increment} 
or \emph{decrement} the counter i (change it by $\pm 1$).

Programs also exploit a trivalent (ternary) operator:
\begin{center}
\begin{Pcode}[]
if (...) then (...) else (...)
\end{Pcode}
\end{center}
The words, while helpful, are unimportant and some languages
replace it with symbols emphasizing it is an operator:
\begin{center}
    \pcode{_?_:_}
\end{center}
Here for example is division with remainder of positive integers
\begin{center}
\begin{Pcode}[]
    div(m,n)=(m>=n)?(div(m-n,n)+(1,0)):(0,m)
\end{Pcode}
\end{center}

\section{Grammar}
What does $\Box+\Box$ and $\Box\cdot \Box$ actually mean?  When I add matrices I
use matrices of the same shape, e.g. both $(2\times 3)$-matrices,  but when I
multiply matrices I often need different shapes, perhaps a $(2\times 3)$-matrix
on the left and a $(3\times 4)$-matrix on the right.  Yet it is a matter of
detail, when I multiply I still multiply to matrices, even of of different
shapes. As a start we can replace the vague $\Box$ notation with a grammar.

Grammars can be specified by \emph{production rules}.  Production rules are
pairs $(left,right)$ where the left-hand side is the name of the production and
the right-hand side is the string of symbols we want to match with that
production.  For example, to accept $0$ as ``zero'' I would include
$(\text{zero},0)$, $(\text{Nat},1)$ tells us to accept $1$ as the natural 
number 1, versus $(\text{Reals},1.0)$ which accepts $1.0$ as real number.
Since the use of productions is a ``(after, before)'' we often prefer 
the notation 
\begin{center}
    \code{<left> ::= <right>}
\end{center}
Once we introduce a production rule we can clarify if we want the symbol 
to be read through the lens of the rule by placing the name as a 
tag on the symbol separated by a colon.  So far we can fathom 
that hte operators encountered take on production rules like these:
\begin{itemize}
\item 
    \code{<zero> ::= 0} is a production so  $0:\text{zero}$.
\item 
    \code{<Nat> ::= 1} is a production so  $1:\text{Nat}$.
    \item 
    \code{<Nat> ::= <Nat> + <Nat>} is a production so  $(2+3):\text{Nat}$.
\item 
    \code{<List> ::= cat <List> <List>} means\\
    (cat [1,2,3] [4,5,6]):List. 
\item 
    \code{<List> ::= <List> + <List>} hence\\
    ([1,2,3] + [4,5,6]):\text{List}. 
\end{itemize}
The trick of note is that the right-hand side of a production 
rule can include reference to other productions.  This means 
that if we have already match part of a string of symbols to those 
productions we can build up from there recursively.  Such recursion 
is known as \emph{primitive recursion} because it always goes backward 
in history until to some starting point.  It is not for example 
capable of considering things like limits of infinite loops and such.

Notice we have not declared yet what grammar might be intended to make 
lists or natural numbers but if they were known to us (and indeed 
all these will mean is what we expect from examples) then the grammars 
clarify how to use natural numbers and lists with the operators of 
$+$ and cat.

\begin{itemize}
\item 
    \code{<Boolean> ::= if <Boolean> then <A> else <B><List> + <List>} hence\\
    ([1,2,3] + [4,5,6]):\text{List}. 

\item 
    \code{<Matrix> ::= <Matrix>  <Matrix>} leads to accepting
    $\displaystyle \begin{bmatrix} 1 & 0 \\ 2 & 7\end{bmatrix}
    + \begin{bmatrix} -1 & 0 \\ 0 & 1 \end{bmatrix}:\text{List}$. 
\end{itemize}
As a warning, this version of grammar does not block against 
illegal operations.  For example the 
\[
    \begin{bmatrix} 1 & 0 & 8 \\ 2 & 7 & -1\end{bmatrix}
+ \begin{bmatrix} -1 & 0 \\ 0 & 1 \end{bmatrix}:\text{List}.
\] 

out that the matrices we wish 
to multiply have compatible dimensions but it does for example 
prevent us from adding matrices to polynomials and other silliness.

