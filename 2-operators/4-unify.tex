
\section{Operators that unify}
Sometimes the products we want breakdown in small dimensions or over small number systems.
Take the inner product 
\begin{align*}
    \langle \vec{u}\mid \vec{v}\rangle & \defeq \sum_{i} u_i v_i
\end{align*}
From this we derive lengths and right angles, reflections, and rotations.
These are essential for geometry.
Lengths $|\vec{u}|$ are the solutions to $x^2=\langle \vec{u}|\vec{u}\rangle$, that is,
\begin{align*}
    |\vec{u}| = \sqrt{\langle \vec{u}|\vec{u}\rangle}.
\end{align*}
This is the perfect definition because it gives us the pythagorean theorem.
That is, $\langle \vec{u}|\vec{v}\rangle=0$ implies
\begin{align*}
    |\vec{u}+\vec{v}|^2 & = \langle \vec{u}+\vec{v}|\vec{u}+\vec{v}\rangle\\
    & = \sum_i (u_i+v_i)^2\\
    & = \sum_i (u_i^2+2u_i v_i+v_i^2)\\
    & = \sum_i u_i^2+2\sum_i u_i v_i + \sum_i v_i^2\\
    & = |\vec{u}|^2+2\langle \vec{u}|\vec{v}\rangle +|\vec{v}|^2\\
    & = |\vec{u}|^2+|\vec{v}|^2.
\end{align*}
In fact looking closer we see the pythagorean theorem recovers the inner product
\begin{align*}
    2\langle \vec{u}|\vec{v}\rangle \defeq  
        |\vec{u}+\vec{v}|^2-|\vec{u}|^2-|\vec{v}|^2.
\end{align*}
However we could only solve for $\langle \vec{u}|\vec{v}\rangle$ if we can 
cancel the multiplication by 2.    Obviously this cannot be done if $2=0$.
In this situation we can ask, why not start over?  Instead of starting geometry 
from inner products, which we now realize has less information than lengths,
we can start with length as our principle operator, in fact, length squared 
is what we need because why should square-roots even exist.  This is why 
modern geometry uses \emph{quadratic forms}, not inner products, to 
define orthogonal geometry.

A similar problem is lurking with  the Jordan products introduced a multiplication by $2$.
If $2=0$ this becomes unsolvable, but removing the 2 does not really solve 
our problems.  For example some of the power of $\bullet$ is that we 
can explore when $A\bullet A=A$, which means multiplying by $A\bullet A-A$ 
must have $0$ and $1$ eigenvalues.  That idea makes sense even when $2=0$ 
but when $2=0$, $AA+AA=0$ and so it seems that $A\bullet A=0$ and we lost 
this vital information.  Instead, modern Jordan algebras are introduced by 
a quadratic product 
\begin{align*}
    U_A(B) & \defeq ABA.
\end{align*}

As a last example let consider lines.   Part of the success of algebra and 
geometry was the realization that lines are described by the equations $y=mx+b$.
Yet that requires a number of hard to meet conditions on geometry beyond the obvious 
point-line intersection rules.  So when it comes to very general geometries 
it was not know how to describe lines algebraically as $y=mx+b$ because 
appropriate choices of $+$ and $\cdot$ were not known.
So Marshall Hall decided we could simply invent a trivalent (ternary) operator
\[
    -\otimes-\oplus -
\]
This is merely suggestive notation.  It allows us to write an equation 
that looks like our line equation:
\[
    y=m\otimes x\oplus b
\] 
yet this is not an amalgum of two operators just one single trivalent operator.
With this trivalent product, Hall was able to associate every 
projective plane to coordinates in some ``ternary ring''.  Once you have such a ternary ring you 
can go to work to see if it might actually decompose into two binary operations of multiplicaton 
and addition, e.g.\ by locating a ``one'' and a ``zero'' where $x=1\otimes x\oplus 0$.  Then 
you reverse the process and define $m\cdot x\defeq m\otimes x\oplus 0$ and $x+b\defeq 1\otimes x\oplus b$
to get a more familiar ring-like structure.


Within algebra it is often possible to avoid special cases in small dimensions 
or small characteristics by replacing products with products that solve higher 
degree polynomials which have solutions in all situations.  