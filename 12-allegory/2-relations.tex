
\section{Relations}
Imagine you want to explain linear algebra.  You work up to a concept of 
$\mathbb{Z}$-module, each is a set $V$ with some operations $+$ and $\cdot$. You would likely
consider subspaces, $U\leq V$, which you dutifully show to be subsets that are
closed to $+$ and $\cdot$ and $0$. You show the person linear mappings $f:V\to
W$---those are linear maps that preserve $+$ and $\cdot$.  You might even dabble
with quotients, needing an equivalence relation $u\equiv v\pmod{K}$ for which
$+$ and $\cdot$ are well-defined.  There is a lot wrapped up in this already and
them come many more questions.  What about a subspace of a subspace.  What about
quotient of a subspace? What happens when you apply a linear map to a quotient
of as subspace? With something this well-known it is surprising how many
branches of abstraction we seem to need to follow to build and understanding.
But perhaps the fact that it all holds together is a sign of a simpler process
behind it all. Perhaps, congruence relations, linear maps, subspace and more are
really one unified concept.


Consider how we define the concepts.  Lets look first at just the addition.
\begin{align*}
    U\subset V\text{ is a subspace} & \Leftrightarrow (\forall u,\acute{u}\in U)(u+\acute{u}\in U)\\
    f:U\to V\text{ is linear} & \Leftrightarrow (\forall u,\acute{u}\in U)(f(u+\acute{u})=f(u)+f(\acute{u}))\\
\end{align*}


First we can turn a function into its graph.
\begin{align*}
    gr&:(A\to B)\to (A\times B\to \Prop)
    & 
    gr(f)(a,b) & \defeq f(a)=_B b.
\end{align*}
As a general remark, there is not stable definition for the 
equality of two typed functions.  Recall that typing a function is 
merely the act of taking a program (a $\lambda$-expression) and 
attaching to it a proof that given inputs of the domain type, the outputs 
will have the codomain's type.  This means the actual process is subject 
to the strings of the program as well as choices made by whomever 
performs the substitution.  Do we rewrite left-to-right or some other way?
Two such strings could be quite different but produce the same graph.
Thus if equality of typed functions is held on the level, known as 
\emph{intentional} equality, then they will not be equal very often and $gr$ will be a many-to-one 
function.  On the other hand it is reasonable to overlook certain differences 
as is done in almost all situations.  On the extreme end of that scale 
is to declare to functions as equal if they have equal graphs.  That is 
known as \emph{extensional} equality.  Unfortunately it can be shown 
that such an equality is undecideable which limits its practical use.
Some systems of logic such as classical ZF Set Theory assume therefore by 
axiom that all functions however defined have an extensional equality.
That is, no property applied to two functions can notice a difference 
once they are known to be equal.


Fix a context-free grammar $\sigma$ which consists of terminal symbols 
we think of as constants, and non-terminal symbols we think of as operators
along with production rules.


Given an algebra $A$ modeling the theory,
an \emph{algebraic relation} is function $P:\prod_{i:I} A_i\to \Prop$ if 
\begin{align*}
    \begin{array}{cc}
        & P(a_{11}, \cdots, a_{1m})\\
        & \vdots \\
        \langle\cdots\rangle & P(a_{m1}, \cdots, a_{mn})\\
    \hline
       & P(\langle a_{*1}\rangle,\ldots \langle a_{*n}\rangle)
    \end{array}
\end{align*}

\subsection{Heteromorphisms}


\section{Substructure}
A function $P:\prod_{i:I}(A_i\to \Prop)$ describes a substructure.
\begin{center}
    \begin{tikzcd}
        \prod_{i:I}A_i \arrow[r, "\langle\cdots\rangle"] & A_0\\
        \prod_{i:I}\bigsqcup_{a_i:A_i}P(a_i) \arrow[u,hook]\arrow[r,"closed"] 
            & \bigsqcup_{a_0:A_0}P_0(a_0)\arrow[u, hook]
    \end{tikzcd}
\end{center}