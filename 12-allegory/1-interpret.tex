\section{Models interpreted in a language}
\index{models}
We know grammar lets us write down algebra and its formulas but so 
far we have built much of the algebra we see around us.  Formulas 
are not the stuff of numbers.  So the idea now is to evaluate the 
formulas on other data. The idea is to assign data types to a 
bunch of the tag names of the grammar and then use the production 
rules to identify the operations we need between the types.

So let us begin with a formal context-free grammar 
\[ 
    \sigma=(\Sigma,\mathcal{N},\mathcal{P},\mathcal{S}).
\] 
(See Chapter~\ref{chp:cfg}.)
We assume its alphabet is $\Sigma$, its tag names are $\mathcal{N}$, 
and its production rules are $P\subset \mathcal{N}\times (\Sigma\sqcup \mathcal{N})^*$.
We will begin with the starting rules being $\mathcal{S}=\mathcal{N}$ and later remark on 
how to address the case when $S$ is a proper subset of $\mathcal{N}$.

First we need to assign to every tag-name a type.  We can see this 
as a function $A\mapsto \bar{A}$ of type
\begin{align*}
    \mathcal{N}\to \Type.
\end{align*}
The person describing a model of the algebra is responsible for 
creating this assignment.  Next we need to extend this function 
to work on strings $(\mathcal{N}\sqcup \Sigma)^*$ 
\begin{align*}
    \bar{w} & \defeq \begin{cases}
        \bar{A} & x=\iota_{\mathcal{N}}(A)\\
        \{t\} & x=\iota_{\Sigma}(t)\\
        \bar{y}\times \bar{z} & x=yz
    \end{cases}
\end{align*}
We assume 
our algebra comes with an assignment
\begin{align*}
    ops:\prod_{(A,w):P}\prod_{t\in w}\overline{base}(t)\to base(A).
\end{align*}


\begin{example}
    Fix the grammar \code{<<Nat>> ::= 0 | S <Nat>}.
    Then define 
    \begin{align*}
        & \{Nat\}\to \Type & \overline{Nat} \defeq \mathbb{C}[x]\\
        ops_0 & : \{0\}\to \mathbb{C}[x] &  ops_0(0) & \defeq 1\\
        ops_S & : \{S\}\times \mathbb{C}[x]\to \mathbb{C}[x] &  ops_S(S,a(x)) & \defeq a(x)x.
    \end{align*}
    Thus $\{1,x,xx,\ldots, x^n,\ldots\}$ is interpreted in the language 
    of natural numbers.
\end{example}

We also notice that 
the constants do not affect the definition of any function and they can be 
omitted, but including them can have the effect of removing ambiguity and thus 
maintaining a bijection with the original production rules.


Now if we consider a more complicated grammar we may have several production rules 
meant to aid in explaining the language.  Let us recall the one we used for strings
where we out-sourced our use of characters.
\begin{center}
\begin{Gcode}[]
<Char> ::= a | b | c 
<<String<Char>>> ::=
                  | <Char> <String<Char>>
\end{Gcode}
\end{center}
Here the tags are $N=\{$\text{Char}, \text{String<Char>}$\}$ but the 
only starting tag is \code{String<Char>}. We can get ride of this by simply 
copying into the start tags all the options of the \code{Char} tag.
\begin{center}
\begin{Gcode}[]
<<String_abc>> ::= 
                | a <String_abc>
                | b <String_abc>
                | c <String_abc>
\end{Gcode}
\end{center}
Now we have a grammar where $S=N$, which we have already seen how to interpret.

An alternative is to interpret all the tags with a base which means to also 
include further operators.  Here's an example with the string grammar.
\begin{center}
\begin{minipage}{0.4\textwidth}
\begin{Gcode}[]
<Char> ::= a
    | b
    | c 

<<String<Char>>> ::= $\epsilon$
    | <Char> <String<Char>>
\end{Gcode}
\end{minipage}
\hfill 
\begin{minipage}{0.5\textwidth}
\begin{align*}
ops_a &:\{a\}\to \overline{Char}\\
ops_b &:\{b\}\to \overline{Char}\\
ops_c &:\{c\}\to \overline{Char}\\
ops_{\epsilon} & : \{\epsilon\} \to \overline{String-abc}\\
ops_{abc} & : \overline{Char}\times \overline{String-abc} \to \overline{String-abc}
\end{align*}    
\end{minipage}
\end{center}
    

% In fact it is an often sought after 
% quality of grammars to add production rules to reduce the complexity of understanding 
% what strings are accepted.  For context-free grammars one can achieve a form 
% where every production rule is empty \code{<A>::=}, uni-valent \code{<A>::= t}
% for a character $t:\Sigma$, or bi-valent \code{<A>::= <B><C>}. This is 
% known as Chompsky Normal Form.\index{Chompsky Normal Form}
% We achieve this by adding new production rules to break apart ones of higher 
% valence.  For example
% \begin{center}
% \begin{Gcode}[]
% <<A>> ::= [<A>,<A>,<A>]
% \end{Gcode}
% \end{center}
% could become
% \begin{center}
% \begin{Gcode}[]
%    <Third> ::= ,<A>
%      <Mid> ::= <A><Third>
%   <Second> ::= ,<Mid>
% <Interior> ::= <A><Second>
%     <Open> ::= <Interior>]
%      <<A>> ::= [<Open>
% \end{Gcode}
% \end{center}
% As a result of intermediate tags we cannot generally assume every tag 
% is a start symbol.  These other tags are therefore used in the construction 
% of the symbols we want.  So in an interpretation of model in a language 
% we would like to think that the start symbols need actual data types 
% and the further auxillary tags are merely there as helpers.  For example,
% if we encounter the grammar \code{<<A>> ::= [<A>,<A>,<A>]}
% we seem to have need of a single type $A$ and tri-valent function 
% $[-,-,-]:A^3\to A$.  Yet when we are handed this same grammar in Chompsky 
% Normal Form we suddenly loose track of the original tri-valent map 
% in favor of a long list of bi-valent maps chained together.
% \begin{align*}
%     & \{,\}\times \bar{A}\to \overline{Third}\\
%     & \bar{A}\times \overline{Third}\to \overline{Mid}\\
%     & \{,\}\times \overline{Mid}\to \overline{Second}\\
%     & \bar{A}\times \overline{Second}\to \overline{Interior}\\
%     & \overline{Interior}\times \{]\}\to \overline{Open}\\
%     & \{[\}\times \overline{Open}\to \bar{A}\\
% \end{align*}
% The single start symbol exposes that we cannot use each of the operations 
% independently in the interpretation.  Instead we much chain them together as follows.
% \begin{align*}
%     & \{[\}\times 
%         \overline{Open}
%     \to \bar{A}\\
%     & \{[\}\times 
%         \overline{Interior}
%     \times \{]\}\to \bar{A}\\
%     & \{[\}\times \bar{A}\times 
%         \overline{Second}
%     \times \{]\}\to \bar{A}\\
%     & \{[\}\times \bar{A}\times  \{,\}
%         \times \overline{Mid}
%     \times \{]\}\to \bar{A}\\
%     & \{[\}\times \bar{A}\times  \{,\}\times \bar{A}\times 
%         \overline{Third}
%     \times \{]\}\to \bar{A}\\
%     & \{[\}\times \bar{A}\times  \{,\}\times \bar{A}\times \{,\}\times \bar{A}
%     \times \{]\}\to \bar{A}.
% \end{align*}
% So we see that we can match the original intent of a single tri-valent operator 
% by interpreting all the productions as partial evaluations of the 
% tri-valent operator.  So in the case where the start symbols are a proper 
% subset of the tags we can in a sense reverse the process of dividing production 
% rules into subrules and instead compose them until the only remaining tags 
% are start tags.  Then we interpret the language as above.  

\begin{definition}
    An \emph{interpretation} of a formal context-free grammar $\sigma=(\Sigma,N,P,S)$ 
    is pair $A\defeq (base,ops)$ which assign to each start tag a type and 
    to each production rule a function whose domain and codomain are compatible 
    with the base interpretation of the start tags.  We write 
    \[ 
        A\vDash_{\sigma}
    \]
\end{definition}

This notation should seem pregnant, a sentence ending without an direct object.
This anticipates our later need to follow this notation by formulas that express qualities of 
the interpretation.  For example, perhaps $[a,b,c]=[b,c,a]=[b,a,c]$ in the specific 
model.  We shall then write     
\[ 
    A\vDash_{\sigma} [a,b,c]=[b,c,a]=[b,a,c].
\]

