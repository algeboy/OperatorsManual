\section{Replacing operations}
One day  $+$ means to add natural numbers, the next day 
polynomials, later matrices.  
You can even add colors ``Yellow=Blue+Green''. When you program 
you learn to add strings
\begin{center}
\begin{notebookin}
print "Algebra " + " is " + " computation"
\end{notebookin}
\begin{notebookout}
Algebra is computation
\end{notebookout}
\end{center}
If we focus on our 
speech we find more expansive uses:
``add the flour, water, yeast, and salt'' or  
``count each household, then add''.

\subsection{Serializing}
Chompsky had and advantage that written human languages are largely serial in
that the character, words, and sentences read in one direction.  For example
left-to-right top-to-bottom.  In mathematics this idea is often stretched to
include spacial dimensions of which there really is no proper starting point,
for example:
\begin{align*}
    x^2 \qquad u_i \qquad \frac{9}{17}\qquad \int_{-2}^2 \sin x \text{d}x.
\end{align*}
In this case we can usually opt to ``serialize'' the diagram by drawing 
a path through all the symbols detailing the order in which we will parse 
the information.  For example
\begin{center}
    \begin{tikzpicture}
        \node (x) at (0,1) {$x$};
        \node (2) at (0.2,1.2) {$2$};
        \node (s) at (2,1) {x\^{}2}; 
        \draw[blue,->] (x) edge[thick,out=120,in=120,looseness=5] (2);

        \node (x) at (4,1) {$u$};
        \node (2) at (4.2,0.8) {$i$};
        \node (s) at (6,1) {u{\_}i}; 
        \draw[blue,->] (x) edge[thick,out=60,in=60,looseness=5] (2);

        \node (x) at (0,-1) {$\frac{9}{17}$};
        \node (s) at (2,-1) {9/17}; 
        \draw[blue,->] (x) edge[thick,out=90,in=-180,looseness=5] (x);
        \draw[blue,->] (x) edge[thick,out=0,in=-90,looseness=5] (x);

        \node (x) at (4,-1) {$\displaystyle\int_{-2}^2 $};
        \node (s) at (6,-1) {$\sin x$};
        \node (d) at (6.75,-1) {d$x$};
        \node (t) at (9,-1) {int{\_-2}{\^{}}2 $\sin x$ d$x$}; 
        
        \draw[blue,->] (x) edge[thick,out=180,in=90,looseness=3] (x);
        \draw[blue,->] (x) edge[thick,out=45,in=-45,looseness=3] (x);
        \draw[blue,->] (x) edge[thick,out=-90,in=-90,looseness=3] (s);
        \draw[blue,->] (s) edge[thick,out=90,in=90,looseness=3] (d);
    \end{tikzpicture}
\end{center}

\subsection{Homogeneous Operators}
So addition is clearly variable, but on the other hand the following substitution 
seems a clear misunderstanding.
\[
    (2+3)[+\leftrightarrows 7]=273.
\]
One way to communicate these implied rules is to add to our grammar.
To communicate the rules we can 
So while one aspect of addition depends on some inputs, the total 
number being its \emph{valence}, it also depends on a grammar.
It may be \emph{infix} $2+3$ as we commonly 
use with arithmetic.  We have a language for this.
\begin{center}
    \begin{minipage}{0.4\textwidth}
\begin{Gcode}[]
<A> ::= <A> + <A> 
\end{Gcode}
\end{minipage}
\end{center}
Because this has only one type of data, e.g. everything here was an integer, 
 we call this operator \emph{homogeneous} operator.es.
To express the pattern symbolically we can resort 
to schematic method like the following.
\[
    \Box+\Box
\]
Addition may also be \emph{prefix} $+,2,3$ as in the recipe instructions,
or it could be \emph{postfix} $2,3,+$; as in the census illustration. 
In diagrams:
\begin{center}
\begin{minipage}{0.4\textwidth}
\centering
\begin{Gcode}[]
<A> ::= + <A> <A> 
\end{Gcode}
$+ \Box \Box$
\hspace{1in}
\end{minipage}
\hfill
\begin{minipage}{0.4\textwidth}
\centering
\begin{Gcode}[]
<A> ::= <A> <A> +
\end{Gcode}
$\Box \Box +$
\end{minipage}    
\end{center}    

The variations in grammar are like any language 
where there could be a dialect that evolves the operator's grammar and lexicon.
 HP calculators were postfix for some time to match engineering requirements.
A program to add two lists could get away with the following linguistic drift:
\begin{center}
\begin{notebookin}
cat [3,1,4] [1,5,9]
[3,1,4] + [1,5,9]
\end{notebookin}
\begin{notebookout}[2]
[3,1,4,1,5,9]
[4,6,13]
\end{notebookout}
\end{center}
Using \texttt{cat} reminded us to concatenate and avoided confusion with the
later $+$ concept.  It was the better choice. Challenge yourself to see both as
addition and you will find addition everywhere. 

Addition  may be with two or more terms.  It also may be 
sensitive to order: ``add the food coloring to the vinegar, then add the baking
powder'' is a different to ``add the vinegar and baking powder then the
food coloring''.  To make a manageable theory, algebra needs fewer variations that 
build towards this complexity.

Since we are evolving, we may as well permit multiplication as a bivalent operator
symbol, changing the signature to $\Box \cdot \Box$, i.e. $2\cdot 4$; or
$\Box\Box$, e.g. $xy$.   Avoid $\Box\times \Box$, we need that symbol elsewhere.
These days composition $\Box\circ\Box$ is written as multiplication; so, you can
use that symbol however you like.  


Returning to the silly example 
$(2+3)[+\leftrightarrows 7]=273$.
What we actually want is the ability to replace the place holder $+$ with 
new strings that represent what exactly we wanted to do.  For example 
if we wrote a program 
\begin{center}
    \code{def add(x:Nat,y:Nat):Nat=...}
\end{center}
Then we should want to convert $(2+3)[+\leftrightarrows \code{add}]$ and get 
\code{add(2,3)}.  This is not quite a substitution but we could start by 
just assuming that the task was to do this:
\begin{center}
    (2+3)[+$\leftrightarrows$ \code{add}] = 2~\code{add}~3.
\end{center}
This substitution is less suspicious and in fact there are even programming 
languages that could let you apply the function \code{add} in this way.
Lets write down what is different from the case of replacing $+$ with $7$.
What we could say is that $+$ is not only a variable but it has a role 
in the grammar.  And so we could compare two grammars with different terminal 
alphabets:
\begin{center}
\code{<Nat> ::= <Nat> + <Nat>}\\
\code{<Nat> ::= <Nat> add <Nat>}
\end{center}
And we could observe that 
(2+3)[+$\leftrightarrows$ \code{add}] = 2~\code{add}~3 is somewhat 
justified because the string on the left $2+3$ is accepted by the first grammar 
before the substitution, and the string on the right after the substitution 
is accepted by a nearly identical grammar.  We could say that the two grammars 
are isomorphic.  In fact, if we are engaged in comparing the grammars as 
essentially the same then we can rectify the cosmetic difference of the prefix 
verses post fix.  The following two grammars are also isomorphic.
\begin{center}
\code{<Nat> ::= <Nat> + <Nat>}\\
\code{<Nat> ::= add(<Nat>,<Nat>)}
\end{center}
Therefore, up to the isomorphism in the grammar, both sides of the following 
substitution are accepted identically by the grammar.
\begin{center}
    (2+3)[+$\leftrightarrows$ \code{add}] = add(2,3)
\end{center}


\begin{definition}
    Given two isomorphic grammars, a \emph{grammatically valid} substitution means 
    that given an accepted string $M$ in the language of the first grammar,
    a variable $x$ that occurs as token in the grammar
    then     $M[x\leftrightarrows N]$ is accepted by the same 
    the second grammar using the isomorphic image of the 
    production rules used to accept $M$.
\end{definition}

So in the grammar that accepts $2+3$, the production rule involved 
is \code{<A>::=<A>+<A>}.  When we substitute 
$(2+3)[+\leftrightarrows 7]=273$ we could certainly accept the number 
273, but would be by a different production rule, such as \code{<digit>}, 
which would not be the image of an isomorphic grammar in that case.


\subsection{Heterogeneous operators}
Multiplication however is often more subtle and 
could require a more explicit grammar.  Think of rescaling a vector, we need 
different types of data so our scheme changes.
\begin{center}
% \begin{minipage}{0.6\textwidth}
%     \centering
%     \begin{Gcode}[]
%     <Vec> ::= <Scale> <Vec> 
%     \end{Gcode}
    $\Box = \bigcirc \Box$
    % \end{minipage}    
\end{center}    
This is no longer one data type.  To put words to it we have here a \emph{heterogeneous}
operator whereas the additions we explored before were each \emph{homogeneous}.\index{heterogeneous}\index{homogeneous}

Addition is held to high standards in algebra
(that it will evolve into linear algebra).  So when you are considering a bivalent
operation with few if any good properties, use a multiplication inspired
notation instead.   


\index{bivalent!opeator}\index{binary operator|see{bivalent operator}}
Addition from here on out will be bivalent (also called binary), meaning 
that it requires 2 inputs.  We typically prefer infix grammar $\Box +\Box$.




\index{univalent!opeator}\index{unary operator|see{univalent operator}} Valence
1, also called \emph{univalent} or \emph{unary}, operators include the negative
sign $-\Box$ to create $-2$ as well as the transpose $A^{\dagger}$ of a matrix
$A$. Notice in the case of negative an integer remained an integer, but in the
case of transpose a $(2\times 3)$-matrix becomes a $(3\times 2)$-matrix.
Operators can change the type of data we explore.
 
Programming languages add several others univalent operators
such as \code{++i, --i} which are said to \emph{increment} 
or \emph{decrement} the counter i (change it by $\pm 1$).

Programs also exploit a trivalent (ternary) operator:
\begin{center}
\begin{Pcode}[]
if (...) then (...) else (...)
\end{Pcode}
\end{center}
The words, while helpful, are unimportant and some languages
replace it with symbols emphasizing it is an operator:
\begin{center}
    \pcode{_?_:_}
\end{center}
% Here for example is division with remainder of positive integers
% \begin{center}
% \begin{Pcode}[]
%     div(m,n)=(m>=n)?(div(m-n,n)+(1,0)):(0,m)
% \end{Pcode}
% \end{center}
